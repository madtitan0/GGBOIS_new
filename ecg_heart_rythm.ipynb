{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitbih_database\\100.csv\n",
      "mitbih_database\\100annotations.txt\n",
      "mitbih_database\\101.csv\n",
      "mitbih_database\\101annotations.txt\n",
      "mitbih_database\\102.csv\n",
      "mitbih_database\\102annotations.txt\n",
      "mitbih_database\\103.csv\n",
      "mitbih_database\\103annotations.txt\n",
      "mitbih_database\\104.csv\n",
      "mitbih_database\\104annotations.txt\n",
      "mitbih_database\\105.csv\n",
      "mitbih_database\\105annotations.txt\n",
      "mitbih_database\\106.csv\n",
      "mitbih_database\\106annotations.txt\n",
      "mitbih_database\\107.csv\n",
      "mitbih_database\\107annotations.txt\n",
      "mitbih_database\\108.csv\n",
      "mitbih_database\\108annotations.txt\n",
      "mitbih_database\\109.csv\n",
      "mitbih_database\\109annotations.txt\n",
      "mitbih_database\\111.csv\n",
      "mitbih_database\\111annotations.txt\n",
      "mitbih_database\\112.csv\n",
      "mitbih_database\\112annotations.txt\n",
      "mitbih_database\\113.csv\n",
      "mitbih_database\\113annotations.txt\n",
      "mitbih_database\\114.csv\n",
      "mitbih_database\\114annotations.txt\n",
      "mitbih_database\\115.csv\n",
      "mitbih_database\\115annotations.txt\n",
      "mitbih_database\\116.csv\n",
      "mitbih_database\\116annotations.txt\n",
      "mitbih_database\\117.csv\n",
      "mitbih_database\\117annotations.txt\n",
      "mitbih_database\\118.csv\n",
      "mitbih_database\\118annotations.txt\n",
      "mitbih_database\\119.csv\n",
      "mitbih_database\\119annotations.txt\n",
      "mitbih_database\\121.csv\n",
      "mitbih_database\\121annotations.txt\n",
      "mitbih_database\\122.csv\n",
      "mitbih_database\\122annotations.txt\n",
      "mitbih_database\\123.csv\n",
      "mitbih_database\\123annotations.txt\n",
      "mitbih_database\\124.csv\n",
      "mitbih_database\\124annotations.txt\n",
      "mitbih_database\\200.csv\n",
      "mitbih_database\\200annotations.txt\n",
      "mitbih_database\\201.csv\n",
      "mitbih_database\\201annotations.txt\n",
      "mitbih_database\\202.csv\n",
      "mitbih_database\\202annotations.txt\n",
      "mitbih_database\\203.csv\n",
      "mitbih_database\\203annotations.txt\n",
      "mitbih_database\\205.csv\n",
      "mitbih_database\\205annotations.txt\n",
      "mitbih_database\\207.csv\n",
      "mitbih_database\\207annotations.txt\n",
      "mitbih_database\\208.csv\n",
      "mitbih_database\\208annotations.txt\n",
      "mitbih_database\\209.csv\n",
      "mitbih_database\\209annotations.txt\n",
      "mitbih_database\\210.csv\n",
      "mitbih_database\\210annotations.txt\n",
      "mitbih_database\\212.csv\n",
      "mitbih_database\\212annotations.txt\n",
      "mitbih_database\\213.csv\n",
      "mitbih_database\\213annotations.txt\n",
      "mitbih_database\\214.csv\n",
      "mitbih_database\\214annotations.txt\n",
      "mitbih_database\\215.csv\n",
      "mitbih_database\\215annotations.txt\n",
      "mitbih_database\\217.csv\n",
      "mitbih_database\\217annotations.txt\n",
      "mitbih_database\\219.csv\n",
      "mitbih_database\\219annotations.txt\n",
      "mitbih_database\\220.csv\n",
      "mitbih_database\\220annotations.txt\n",
      "mitbih_database\\221.csv\n",
      "mitbih_database\\221annotations.txt\n",
      "mitbih_database\\222.csv\n",
      "mitbih_database\\222annotations.txt\n",
      "mitbih_database\\223.csv\n",
      "mitbih_database\\223annotations.txt\n",
      "mitbih_database\\228.csv\n",
      "mitbih_database\\228annotations.txt\n",
      "mitbih_database\\230.csv\n",
      "mitbih_database\\230annotations.txt\n",
      "mitbih_database\\231.csv\n",
      "mitbih_database\\231annotations.txt\n",
      "mitbih_database\\232.csv\n",
      "mitbih_database\\232annotations.txt\n",
      "mitbih_database\\233.csv\n",
      "mitbih_database\\233annotations.txt\n",
      "mitbih_database\\234.csv\n",
      "mitbih_database\\234annotations.txt\n",
      "mitbih_database\\mitbih_database\\100.csv\n",
      "mitbih_database\\mitbih_database\\100annotations.txt\n",
      "mitbih_database\\mitbih_database\\101.csv\n",
      "mitbih_database\\mitbih_database\\101annotations.txt\n",
      "mitbih_database\\mitbih_database\\102.csv\n",
      "mitbih_database\\mitbih_database\\102annotations.txt\n",
      "mitbih_database\\mitbih_database\\103.csv\n",
      "mitbih_database\\mitbih_database\\103annotations.txt\n",
      "mitbih_database\\mitbih_database\\104.csv\n",
      "mitbih_database\\mitbih_database\\104annotations.txt\n",
      "mitbih_database\\mitbih_database\\105.csv\n",
      "mitbih_database\\mitbih_database\\105annotations.txt\n",
      "mitbih_database\\mitbih_database\\106.csv\n",
      "mitbih_database\\mitbih_database\\106annotations.txt\n",
      "mitbih_database\\mitbih_database\\107.csv\n",
      "mitbih_database\\mitbih_database\\107annotations.txt\n",
      "mitbih_database\\mitbih_database\\108.csv\n",
      "mitbih_database\\mitbih_database\\108annotations.txt\n",
      "mitbih_database\\mitbih_database\\109.csv\n",
      "mitbih_database\\mitbih_database\\109annotations.txt\n",
      "mitbih_database\\mitbih_database\\111.csv\n",
      "mitbih_database\\mitbih_database\\111annotations.txt\n",
      "mitbih_database\\mitbih_database\\112.csv\n",
      "mitbih_database\\mitbih_database\\112annotations.txt\n",
      "mitbih_database\\mitbih_database\\113.csv\n",
      "mitbih_database\\mitbih_database\\113annotations.txt\n",
      "mitbih_database\\mitbih_database\\114.csv\n",
      "mitbih_database\\mitbih_database\\114annotations.txt\n",
      "mitbih_database\\mitbih_database\\115.csv\n",
      "mitbih_database\\mitbih_database\\115annotations.txt\n",
      "mitbih_database\\mitbih_database\\116.csv\n",
      "mitbih_database\\mitbih_database\\116annotations.txt\n",
      "mitbih_database\\mitbih_database\\117.csv\n",
      "mitbih_database\\mitbih_database\\117annotations.txt\n",
      "mitbih_database\\mitbih_database\\118.csv\n",
      "mitbih_database\\mitbih_database\\118annotations.txt\n",
      "mitbih_database\\mitbih_database\\119.csv\n",
      "mitbih_database\\mitbih_database\\119annotations.txt\n",
      "mitbih_database\\mitbih_database\\121.csv\n",
      "mitbih_database\\mitbih_database\\121annotations.txt\n",
      "mitbih_database\\mitbih_database\\122.csv\n",
      "mitbih_database\\mitbih_database\\122annotations.txt\n",
      "mitbih_database\\mitbih_database\\123.csv\n",
      "mitbih_database\\mitbih_database\\123annotations.txt\n",
      "mitbih_database\\mitbih_database\\124.csv\n",
      "mitbih_database\\mitbih_database\\124annotations.txt\n",
      "mitbih_database\\mitbih_database\\200.csv\n",
      "mitbih_database\\mitbih_database\\200annotations.txt\n",
      "mitbih_database\\mitbih_database\\201.csv\n",
      "mitbih_database\\mitbih_database\\201annotations.txt\n",
      "mitbih_database\\mitbih_database\\202.csv\n",
      "mitbih_database\\mitbih_database\\202annotations.txt\n",
      "mitbih_database\\mitbih_database\\203.csv\n",
      "mitbih_database\\mitbih_database\\203annotations.txt\n",
      "mitbih_database\\mitbih_database\\205.csv\n",
      "mitbih_database\\mitbih_database\\205annotations.txt\n",
      "mitbih_database\\mitbih_database\\207.csv\n",
      "mitbih_database\\mitbih_database\\207annotations.txt\n",
      "mitbih_database\\mitbih_database\\208.csv\n",
      "mitbih_database\\mitbih_database\\208annotations.txt\n",
      "mitbih_database\\mitbih_database\\209.csv\n",
      "mitbih_database\\mitbih_database\\209annotations.txt\n",
      "mitbih_database\\mitbih_database\\210.csv\n",
      "mitbih_database\\mitbih_database\\210annotations.txt\n",
      "mitbih_database\\mitbih_database\\212.csv\n",
      "mitbih_database\\mitbih_database\\212annotations.txt\n",
      "mitbih_database\\mitbih_database\\213.csv\n",
      "mitbih_database\\mitbih_database\\213annotations.txt\n",
      "mitbih_database\\mitbih_database\\214.csv\n",
      "mitbih_database\\mitbih_database\\214annotations.txt\n",
      "mitbih_database\\mitbih_database\\215.csv\n",
      "mitbih_database\\mitbih_database\\215annotations.txt\n",
      "mitbih_database\\mitbih_database\\217.csv\n",
      "mitbih_database\\mitbih_database\\217annotations.txt\n",
      "mitbih_database\\mitbih_database\\219.csv\n",
      "mitbih_database\\mitbih_database\\219annotations.txt\n",
      "mitbih_database\\mitbih_database\\220.csv\n",
      "mitbih_database\\mitbih_database\\220annotations.txt\n",
      "mitbih_database\\mitbih_database\\221.csv\n",
      "mitbih_database\\mitbih_database\\221annotations.txt\n",
      "mitbih_database\\mitbih_database\\222.csv\n",
      "mitbih_database\\mitbih_database\\222annotations.txt\n",
      "mitbih_database\\mitbih_database\\223.csv\n",
      "mitbih_database\\mitbih_database\\223annotations.txt\n",
      "mitbih_database\\mitbih_database\\228.csv\n",
      "mitbih_database\\mitbih_database\\228annotations.txt\n",
      "mitbih_database\\mitbih_database\\230.csv\n",
      "mitbih_database\\mitbih_database\\230annotations.txt\n",
      "mitbih_database\\mitbih_database\\231.csv\n",
      "mitbih_database\\mitbih_database\\231annotations.txt\n",
      "mitbih_database\\mitbih_database\\232.csv\n",
      "mitbih_database\\mitbih_database\\232annotations.txt\n",
      "mitbih_database\\mitbih_database\\233.csv\n",
      "mitbih_database\\mitbih_database\\233annotations.txt\n",
      "mitbih_database\\mitbih_database\\234.csv\n",
      "mitbih_database\\mitbih_database\\234annotations.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('mitbih_database'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution1D, Flatten, Dense, Dropout, Softmax, MaxPooling1D, AveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['N', 'L', 'R', 'A', 'V']\n",
    "n_classes = len(classes)\n",
    "count_classes = [0]*n_classes\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/mitbih-database\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(os\u001b[38;5;241m.\u001b[39mwalk(path))[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m records\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m      4\u001b[0m annotations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = '/kaggle/mitbih-database'\n",
    "filenames = next(os.walk(path))[2]\n",
    "records=list()\n",
    "annotations=list()\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    \n",
    "    if(file_extension=='.csv'):\n",
    "        records.append(path+'/'+filename+file_extension)\n",
    "    else:\n",
    "        annotations.append(path+'/'+filename+file_extension)\n",
    "\n",
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_signal=[]\n",
    "with open(records[6],'r') as csvfile:\n",
    "    filereader = csv.reader(csvfile,delimiter=',',quotechar='|')\n",
    "    row_index = -1\n",
    "    for row in filereader:\n",
    "        if(row_index >= 0):\n",
    "            temp_signal.insert(row_index, int(row[1]))\n",
    "        row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_signal[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(temp_signal[:700])\n",
    "plt.xlabel('Samples', fontsize=15)\n",
    "plt.ylabel('Voltage (Millivolts)', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig('before_preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2signal=temp_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04 # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "  #  print(len(coeffs))\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    return datarec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_signal=denoise(temp_signal)\n",
    "plt.plot(temp_signal[:700])\n",
    "plt.xlabel('Samples', fontsize=15)\n",
    "plt.ylabel('Voltage (Millivolts)', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig('after_denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_signal = stats.zscore(temp_signal)\n",
    "plt.plot(temp_signal[:700])\n",
    "plt.xlabel('Samples', fontsize=15)\n",
    "plt.ylabel('Voltage (Millivolts)', fontsize=15)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig('after_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Denoising, Scaling, Classes Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list()\n",
    "y=list()\n",
    "window_size=180\n",
    "for r in range(0,len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'r') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|') \n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if(row_index >= 0):\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "\n",
    "        \n",
    "    signals = denoise(signals)\n",
    "    #signals = signals.reshape(-1,1)\n",
    "    signals = stats.zscore(signals)\n",
    "\n",
    "    with open(annotations[r], 'r') as fileID:\n",
    "        data = fileID.readlines() \n",
    "        beat = list()\n",
    "\n",
    "        for d in range(1, len(data)): \n",
    "            splitted = data[d].split(' ') \n",
    "            splitted = filter(None, splitted)\n",
    "            next(splitted) \n",
    "            pos = int(next(splitted)) \n",
    "            arrhythmia_type = next(splitted) \n",
    "            \n",
    "            if(arrhythmia_type in classes):\n",
    "                arrhythmia_index = classes.index(arrhythmia_type)\n",
    "                count_classes[arrhythmia_index] += 1\n",
    "                if(window_size <= pos and pos < (len(signals) - window_size)):\n",
    "                    beat = signals[pos-window_size:pos+window_size]   \n",
    "\n",
    "                    X.append(beat)\n",
    "                    y.append(arrhythmia_index)\n",
    "\n",
    "# data shape\n",
    "print(np.shape(X), np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "while y[i]!=0:\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.title('N (Normal beat) ', fontsize=20)\n",
    "plt.xlabel('samples',fontsize=15);\n",
    "plt.ylabel('Voltage (Millivolts)',fontsize=15)\n",
    "plt.savefig('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y)\n",
    "y_df.head()\n",
    "per_class = y_df[y_df.shape[1]-1].value_counts()\n",
    "print(per_class)\n",
    "plt.figure(figsize=(30,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(per_class, labels=['N', 'L', 'R', 'V', 'A'], colors=['#2085ec','#72b4eb','#0a417a','#8464a0','#cea9bc'],autopct='%1.1f%%', textprops={'fontsize':15})\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()\n",
    "p.savefig('Before_piechart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y)\n",
    "y_df.head()\n",
    "per_class = y_df[y_df.shape[1]-1].value_counts()\n",
    "print(per_class)\n",
    "plt.figure(figsize=(30,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(per_class, labels=['N', 'L', 'R', 'V', 'A'], colors=['#2085ec','#72b4eb','#0a417a','#8464a0','#cea9bc'],autopct='%1.1f%%', textprops={'fontsize':15})\n",
    "plt.show()\n",
    "plt.savefig('Before_piechart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X_reshaped = X.reshape(-1,360,)\n",
    "X_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X_reshaped)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_df = pd.concat([X_df,y_df],axis=1)\n",
    "X_new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=list(range(361))\n",
    "X_new_df = X_new_df.set_axis(ax, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=(X_new_df[X_new_df[X_new_df.shape[1]-1]==0]).sample(n=20000,random_state=42)\n",
    "df_1=X_new_df[X_new_df[X_new_df.shape[1]-1]==1]\n",
    "df_2=X_new_df[X_new_df[X_new_df.shape[1]-1]==2]\n",
    "df_3=X_new_df[X_new_df[X_new_df.shape[1]-1]==3]\n",
    "df_4=X_new_df[X_new_df[X_new_df.shape[1]-1]==4]\n",
    "\n",
    "df_1_upsample=resample(df_1,replace=True,n_samples=7000,random_state=125)\n",
    "df_2_upsample=resample(df_2,replace=True,n_samples=7000,random_state=77)\n",
    "df_3_upsample=resample(df_3,replace=True,n_samples=7000,random_state=103)\n",
    "df_4_upsample=resample(df_4,replace=True,n_samples=7000,random_state=59)\n",
    "\n",
    "X_new_df=pd.concat([df_0,df_1_upsample,df_2_upsample,df_3_upsample,df_4_upsample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class = X_new_df[X_new_df.shape[1]-1].value_counts()\n",
    "print(per_class)\n",
    "plt.figure(figsize=(30,10))\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(per_class, labels=['N', 'L', 'R', 'V', 'A'], colors=['#2085ec','#72b4eb','#0a417a','#8464a0','#cea9bc'],autopct='%1.1f%%',textprops={'fontsize':15})\n",
    "plt.show()\n",
    "plt.savefig('after_piechart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "while y[i]!=0:\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.xlabel('samples',fontsize=15);\n",
    "plt.ylabel('Voltage (Millivolts)',fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "while y[i]!=1:\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.xlabel('samples',fontsize=15);\n",
    "plt.ylabel('Voltage (Millivolts)',fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "while y[i]!=2:\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(X[i]) \n",
    "plt.xlabel('samples',fontsize=15);\n",
    "plt.ylabel('Voltage (Millivolts)',fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "while y[i]!=3:\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.xlabel('samples',fontsize=15);\n",
    "plt.ylabel('Voltage (Millivolts)',fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "while y[i]!=4:\n",
    "    i=i+1\n",
    "\n",
    "plt.plot(X[i])\n",
    "plt.xlabel('samples',fontsize=15);\n",
    "plt.ylabel('Voltage (Millivolts)',fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.savefig('V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(X_new_df, test_size=0.20, random_state=7)\n",
    "\n",
    "print(\"X_train : \", np.shape(train))\n",
    "print(\"X_test  : \", np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train[train.shape[1]-1]\n",
    "target_test=test[test.shape[1]-1]\n",
    "y_train=to_categorical(target_train)\n",
    "y_test=to_categorical(target_test)\n",
    "print(np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:train.shape[1]-1].values\n",
    "X_test = test.iloc[:,:test.shape[1]-1].values\n",
    "X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1],1)\n",
    "print(np.shape(X_train), np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=16, kernel_size=11, padding='same', activation='gelu',input_shape=(360, 1)))\n",
    "# model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "# model.add(Conv1D(filters=32, kernel_size=13, padding='same', activation='gelu'))\n",
    "# model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "# model.add(Conv1D(filters=64, kernel_size=15, padding='same', activation='gelu'))\n",
    "# model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "# model.add(Conv1D(filters=128, kernel_size=17, padding='same', activation='gelu'))\n",
    "# model.add(MaxPooling1D(pool_size=3, strides=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(70,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(Dense(35,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(Dense(5,kernel_regularizer=regularizers.l2(0.0001), bias_regularizer=regularizers.l2(0.0001)))\n",
    "# model.add(Softmax())\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(filters=16, kernel_size=11, strides=1, padding='same' , activation = 'relu', input_shape=(360,1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Convolution1D(filters=32, kernel_size=13, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Convolution1D(filters=64, kernel_size=15, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "\n",
    "model.add(Convolution1D(filters=128, kernel_size=17, strides=1, padding='same' , activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=30, epochs=60, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_test, y_test, batch_size=30, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy',fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.ylabel('accuracy',fontsize=15)\n",
    "plt.xlabel('epoch',fontsize=15)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('accuracy_plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss', fontsize=20)\n",
    "plt.ylabel('loss', fontsize=15)\n",
    "plt.xlabel('epoch', fontsize=15)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('loss_plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[]\n",
    "for element in y_test:\n",
    "    y_true.append(np.argmax(element))\n",
    "prediction_proba=model.predict(X_test)\n",
    "prediction=np.argmax(prediction_proba,axis=1)\n",
    "ax=plt.subplot()\n",
    "custCnnConfMat = confusion_matrix(y_true, prediction)\n",
    "sns.heatmap(custCnnConfMat, annot=True,fmt='d', cmap='Greens',ax=ax)\n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(classes); ax.yaxis.set_ticklabels(classes);\n",
    "plt.savefig('cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cf = classification_report(y_true, prediction, target_names=classes,digits=4)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='/kaggle/working/ecg-sensor-data/ecg.csv'\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_signal=[]\n",
    "index=0\n",
    "for i in ecg:\n",
    "    if i>2:\n",
    "        ecg_signal.append(ecg[index-100:index+100])\n",
    "        index=index+1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(ecg_signal[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = ecg_signal[50]\n",
    "pad = [sig[199]]*80\n",
    "sig = pad + sig \n",
    "sig = sig + pad\n",
    "sig = np.reshape(sig,(360,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[]\n",
    "list.append(sig)\n",
    "list = np.array(list)\n",
    "list.shape\n",
    "y_pred=model.predict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.argmax(y_pred)\n",
    "classes[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = ecg_signal[55]\n",
    "pad = [sig[199]]*80\n",
    "sig = pad + sig \n",
    "sig = sig + pad\n",
    "sig = np.reshape(sig,(360,1))\n",
    "plt.plot(sig)\n",
    "list=[]\n",
    "list.append(sig)\n",
    "list = np.array(list)\n",
    "y_pred=model.predict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.argmax(y_pred)\n",
    "classes[res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_pred=989*[0]+11*[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sensor_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_pred = pd.DataFrame(sensor_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class = sensor_pred[sensor_pred.shape[1]-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,10))\n",
    "# my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "# plt.pie(per_class, labels=['N', 'A'], colors=['#2a9d8f','#d62828'],autopct='%1.2f%%',textprops={'fontsize':11})\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.show()\n",
    "# p.savefig('sensor_pred_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = ecg_signal[56]\n",
    "pad = [sig[199]]*80\n",
    "sig = pad + sig \n",
    "sig = sig + pad\n",
    "w = pywt.Wavelet('sym4')\n",
    "maxlev = pywt.dwt_max_level(len(sig), w.dec_len)\n",
    "coeffs = pywt.wavedec(sig, 'sym4', level=maxlev)\n",
    "print(len(coeffs[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/dpm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 19554,
     "sourceId": 25392,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4024534,
     "sourceId": 7000899,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
